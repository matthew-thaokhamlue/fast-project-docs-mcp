"""
Tests for AI content handling functionality in the hybrid MCP workflow.

These tests verify the save_generated_document and validate_generated_content
functionality for handling AI-generated content from Claude Desktop.
"""

import pytest
import tempfile
import shutil
from pathlib import Path

from document_generator_mcp.services.document_generator import DocumentGeneratorService
from document_generator_mcp.models.core import AIGeneratedContent, ContentValidationResult, DocumentResult


class TestAIContentSaving:
    """Test saving AI-generated content to files."""
    
    @pytest.fixture
    def temp_workspace(self):
        """Create a temporary workspace for testing."""
        temp_dir = Path(tempfile.mkdtemp())
        yield temp_dir
        shutil.rmtree(temp_dir)
    
    @pytest.fixture
    def sample_prd_content(self):
        """Sample PRD content for testing."""
        return """# Product Requirements Document

## Introduction
This PRD outlines the requirements for a user authentication system.

## Objectives
- Implement secure email/password authentication
- Provide seamless user experience
- Ensure data security and privacy

## User Stories
### Story 1: User Login
**As a** registered user  
**I want** to login with my email and password  
**So that** I can access my account securely

**Acceptance Criteria:**
- User can enter email and password
- System validates credentials
- User is redirected to dashboard on success

## Success Metrics
- Login success rate > 95%
- Average login time < 2 seconds

## Constraints and Dependencies
- Must comply with GDPR
- Requires secure password hashing
"""
    
    @pytest.mark.asyncio
    async def test_save_ai_generated_prd(self, temp_workspace, sample_prd_content):
        """Test saving AI-generated PRD content."""
        service = DocumentGeneratorService(output_directory=temp_workspace)
        
        ai_content = AIGeneratedContent(
            document_type="prd",
            content=sample_prd_content,
            filename="AI_GENERATED_PRD.md",
            user_notes="Generated by Claude Desktop",
            validation_requested=True
        )
        
        result = await service.save_ai_generated_content(ai_content)
        
        # Verify DocumentResult
        assert isinstance(result, DocumentResult)
        assert result.file_path.exists()
        assert result.file_path.name == "AI_GENERATED_PRD.md"
        assert result.content == sample_prd_content
        assert "AI-generated PRD document" in result.summary
        
        # Verify file was actually saved
        saved_content = result.file_path.read_text()
        assert saved_content == sample_prd_content
        
        # Verify metadata
        assert result.metadata["document_type"] == "prd"
        assert result.metadata["generation_method"] == "ai_generated"
        assert result.metadata["user_notes"] == "Generated by Claude Desktop"
        assert result.metadata["validation_performed"] is True
    
    @pytest.mark.asyncio
    async def test_save_without_validation(self, temp_workspace, sample_prd_content):
        """Test saving AI content without validation."""
        service = DocumentGeneratorService(output_directory=temp_workspace)
        
        ai_content = AIGeneratedContent(
            document_type="prd",
            content=sample_prd_content,
            filename="NO_VALIDATION_PRD.md",
            validation_requested=False
        )
        
        result = await service.save_ai_generated_content(ai_content)
        
        assert result.metadata["validation_performed"] is False
        assert len(result.warnings) == 0  # No validation warnings
    
    @pytest.mark.asyncio
    async def test_save_with_default_filename(self, temp_workspace, sample_prd_content):
        """Test saving with default filename generation."""
        service = DocumentGeneratorService(output_directory=temp_workspace)
        
        ai_content = AIGeneratedContent(
            document_type="spec",
            content="# Technical Specification\n\nTest content",
            filename="SPEC.md"  # Default pattern
        )
        
        result = await service.save_ai_generated_content(ai_content)
        
        assert result.file_path.name == "SPEC.md"
        assert result.metadata["document_type"] == "spec"


class TestAIContentValidation:
    """Test validation of AI-generated content."""
    
    @pytest.fixture
    def service(self):
        """Create a document generator service for testing."""
        return DocumentGeneratorService()
    
    @pytest.mark.asyncio
    async def test_validate_complete_prd(self, service):
        """Test validation of a complete PRD."""
        complete_prd = """# Product Requirements Document

## Introduction
This is a comprehensive PRD for testing.

## Objectives
- Primary objective
- Secondary objective

## Requirements
- Functional requirement 1
- Functional requirement 2

## User Stories
As a user, I want to test the system so that I can verify it works.

## Acceptance Criteria
- WHEN user performs action THEN system SHALL respond
"""
        
        result = await service.validate_ai_content("prd", complete_prd)
        
        assert isinstance(result, ContentValidationResult)
        assert result.document_type == "prd"
        assert result.is_valid is True
        assert "Introduction" in result.sections_found
        assert "Objectives" in result.sections_found
        assert "Requirements" in result.sections_found
        assert len(result.missing_sections) == 0
    
    @pytest.mark.asyncio
    async def test_validate_incomplete_prd(self, service):
        """Test validation of an incomplete PRD."""
        incomplete_prd = """# Product Requirements Document

## Introduction
This is an incomplete PRD.

## Some Random Section
Random content that doesn't follow the template.
"""
        
        result = await service.validate_ai_content("prd", incomplete_prd)
        
        assert result.is_valid is False
        assert "Introduction" in result.sections_found
        assert "Objectives" in result.missing_sections
        assert "Requirements" in result.missing_sections
        assert len(result.quality_issues) > 0
    
    @pytest.mark.asyncio
    async def test_validate_spec_content(self, service):
        """Test validation of SPEC content."""
        spec_content = """# Technical Specification

## Overview
Technical overview of the system.

## Architecture
System architecture description.

## Components
- Component 1: Description
- Component 2: Description
"""
        
        result = await service.validate_ai_content("spec", spec_content)
        
        assert result.document_type == "spec"
        assert "Overview" in result.sections_found
        assert "Architecture" in result.sections_found
        assert "Components" in result.sections_found
    
    @pytest.mark.asyncio
    async def test_validate_design_content(self, service):
        """Test validation of DESIGN content."""
        design_content = """# Design Document

## System Design
Overall system design approach.

## Data Flow
Description of data flow through the system.

## Implementation
Implementation details and approach.
"""
        
        result = await service.validate_ai_content("design", design_content)
        
        assert result.document_type == "design"
        assert "System Design" in result.sections_found
        assert "Data Flow" in result.sections_found
        assert "Implementation" in result.sections_found
    
    @pytest.mark.asyncio
    async def test_validate_content_quality_issues(self, service):
        """Test detection of content quality issues."""
        poor_quality_content = """# PRD

## Introduction
TODO: Add introduction

## Objectives
[PLACEHOLDER]

TBD - need to define objectives
"""
        
        result = await service.validate_ai_content("prd", poor_quality_content)
        
        assert result.is_valid is False
        assert len(result.quality_issues) > 0
        
        # Should detect placeholder text
        placeholder_issues = [issue for issue in result.quality_issues if "placeholder" in issue.lower() or "todo" in issue.lower()]
        assert len(placeholder_issues) > 0
    
    @pytest.mark.asyncio
    async def test_validate_prd_specific_requirements(self, service):
        """Test PRD-specific validation requirements."""
        prd_without_user_stories = """# Product Requirements Document

## Introduction
Complete introduction.

## Objectives
- Objective 1
- Objective 2

## Requirements
- Requirement 1
"""
        
        result = await service.validate_ai_content("prd", prd_without_user_stories)
        
        # Should detect missing user stories
        user_story_issues = [issue for issue in result.quality_issues if "user stor" in issue.lower()]
        assert len(user_story_issues) > 0
    
    @pytest.mark.asyncio
    async def test_validation_error_handling(self, service):
        """Test validation error handling."""
        # Test with invalid document type
        result = await service.validate_ai_content("invalid_type", "content")
        
        assert result.is_valid is False
        assert result.document_type == "invalid_type"
        assert len(result.quality_issues) > 0
